{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb1a302",
   "metadata": {},
   "source": [
    "# WIP - Restaurant Recommendation Dialog System\n",
    "\n",
    "## Members:\n",
    "- Karpiński, R.R. (Rafał)\n",
    "- Pavan, L. (Lorenzo)\n",
    "- Rodrigues Luchetti, G.L. (Gustavo)\n",
    "- Teunissen, N.D. (Niels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002f13b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from re import search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ee2b71",
   "metadata": {},
   "source": [
    "## Reading 'dialog_acts.dat' into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d20aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dialog_acts.dat', 'r') as f:\n",
    "    data = f.readlines()\n",
    "    data = list(map(lambda x: x.rstrip(\"\\n\").split(\" \", 1), data))\n",
    "    \n",
    "df = pd.DataFrame(np.array(data), columns = ['label', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c08e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inform</td>\n",
       "      <td>im looking for a moderately priced restaurant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inform</td>\n",
       "      <td>any part of town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inform</td>\n",
       "      <td>bistro food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                               text\n",
       "0  inform  im looking for a moderately priced restaurant ...\n",
       "1  inform                                   any part of town\n",
       "2  inform                                        bistro food"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c28b517",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "Looking for null values, irrelevant or noisy text (literally, removing 'tv_noise' and 'noise') and repeated values. Formatting labels into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "485147b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>confirm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>affirm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thankyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>reqalts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>negate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>repeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>restart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>reqmore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label\n",
       "label_id          \n",
       "0           inform\n",
       "1          confirm\n",
       "2           affirm\n",
       "3          request\n",
       "4         thankyou\n",
       "5             null\n",
       "6              bye\n",
       "7          reqalts\n",
       "8           negate\n",
       "9            hello\n",
       "10          repeat\n",
       "11             ack\n",
       "12         restart\n",
       "13            deny\n",
       "14         reqmore"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforming labels into numbers\n",
    "df['label_id'] = df['label'].factorize()[0]\n",
    "label_dict = df[['label','label_id']].drop_duplicates().set_index('label_id')\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1566f39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11472    moderately priced restaurant in the north part...\n",
      "25465                                can i get the address\n",
      "8867                                               address\n",
      "Name: text, dtype: object\n",
      "\n",
      "11472    0\n",
      "25465    3\n",
      "8867     3\n",
      "Name: label_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# X - independent features (excluding target variable).\n",
    "# y - dependent variables (target we're looking to predict).\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], df['label_id'], test_size=0.15, random_state=10\n",
    ")\n",
    "\n",
    "print(X_train.head(3))\n",
    "print()\n",
    "print(y_train.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445dd741",
   "metadata": {},
   "source": [
    "## Building Baseline Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f320600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_matching(text):\n",
    "    \"\"\"\n",
    "    Rule-based prediction of dialog acts based on utterances.\n",
    "    Arguments:\n",
    "        text: an utterance ('can i get the address').\n",
    "        \n",
    "    Returns:\n",
    "        Returns a prediction for the given utterance ('request').\n",
    "    \"\"\"\n",
    "\n",
    "    if search(r'\\bhow about\\b|\\bwhat about\\b|\\banything else\\b|\\bare there\\b|\\bis there\\b|\\bwhat else\\b', df.loc[i,'text']):\n",
    "        return 'reqalts'\n",
    "    elif search(r'\\byes\\b|\\byeah\\b|\\bcorrect\\b', text):\n",
    "        return 'affirm'\n",
    "    elif search(r'\\bthank you\\b', text):\n",
    "        return 'thankyou'\n",
    "    elif search(r'\\bgoodbye\\b|\\bbye\\b', text):\n",
    "        return 'bye'\n",
    "    elif search(r'\\bdoes it\\b|\\bis it\\b|\\bdo they\\b|\\bis that\\b|\\bis there\\b', text):\n",
    "        return 'confirm'\n",
    "    elif search(r'\\bwhat is\\b|\\bwhats\\b|\\bmay i\\b|\\bcould i\\b|\\bwhat\\b|\\bprice range\\b|\\bpost code\\b|\\btype of\\b|\\baddress\\b|\\bphone number\\b|\\bcan i\\b|\\bcould i\\b|\\bcould you\\b|\\bdo you\\b|\\bi want+.address\\b|\\bi want+.phone\\b|\\bi would\\b|\\bwhere is\\b', df.loc[i,'text']):\n",
    "        return 'request'\n",
    "    elif search(r'\\bno\\b|\\bnot\\b', text):\n",
    "        return 'negate'\n",
    "    elif search(r'\\blooking for\\b|\\bdont care\\b|\\bdoesnt matter\\b|\\bexpensive\\b|\\bcheap\\b|\\bmoderate\\b|\\bi need\\b|\\bi want\\b|\\bfood\\b|\\bnorth\\b', text):\n",
    "        return 'inform'\n",
    "    elif search(r'\\bdont\\b', text):\n",
    "        return'deny'\n",
    "    elif search(r'\\bhello\\b', text):\n",
    "        predic'hello'\n",
    "    elif search(r'\\brepeat\\b', text):\n",
    "        predictions.append('repeat')\n",
    "    elif search(r'\\bmore\\b', text):\n",
    "        predictions.append('reqmore')\n",
    "    elif search(r'\\bstart\\b', text):\n",
    "        predictions.append('restart')\n",
    "    elif search(r'\\bokay\\b|\\bkay\\b', text):\n",
    "        predictions.append('ack')\n",
    "    else:\n",
    "        return 'inform'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a11000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_sentence(utterance):\n",
    "    \"\"\"\n",
    "    Rule-based prediction of a dialog act based on a phrase.\n",
    "    Arguments:\n",
    "        utterance: string\n",
    "        \n",
    "    Returns:\n",
    "        Returns the predicted dialog act.\n",
    "    \"\"\"\n",
    "    utterance = utterance.lower()\n",
    "    if search(r'\\bhow about\\b|\\bwhat about\\b|\\banything else\\b|\\bare there\\b|\\bis there\\b|\\bwhat else\\b', utterance):\n",
    "        return 'reqalts'\n",
    "    elif search(r'\\byes\\b|\\byeah\\b|\\bcorrect\\b',utterance):\n",
    "        return 'affirm'\n",
    "    elif search(r'\\bthank you\\b', utterance):\n",
    "        return 'thankyou'\n",
    "    elif search(r'\\bgoodbye\\b|\\bbye\\b', utterance):\n",
    "        return 'bye'\n",
    "    elif search(r'\\bdoes it\\b|\\bis it\\b|\\bdo they\\b|\\bis that\\b|\\bis there\\b', utterance):\n",
    "        return 'confirm'\n",
    "    elif search(r'\\bwhat is\\b|\\bwhats\\b|\\bmay i\\b|\\bcould i\\b|\\bwhat\\b|\\bprice range\\b|\\bpost code\\b|\\btype of\\b|\\baddress\\b|\\bphone number\\b|\\bcan i\\b|\\bcould i\\b|\\bcould you\\b|\\bdo you\\b|\\bi want+.address\\b|\\bi want+.phone\\b|\\bi would\\b|\\bwhere is\\b', utterance):\n",
    "        return 'request'\n",
    "    elif search(r'\\bno\\b|\\bnot\\b', utterance):\n",
    "        return 'negate'\n",
    "    elif search(r'\\blooking for\\b|\\bdont care\\b|\\bdoesnt matter\\b|\\bexpensive\\b|\\bcheap\\b|\\bmoderate\\b|\\bi need\\b|\\bi want\\b|\\bfood\\b|\\bnorth\\b',utterance):\n",
    "        return 'inform'\n",
    "    elif search(r'\\bdont\\b', utterance):\n",
    "        return 'deny'\n",
    "    elif search(r'\\bhello\\b|\\bhi\\b|\\bhey\\b', utterance):\n",
    "        return 'hello'\n",
    "    elif search(r'\\brepeat\\b', utterance):\n",
    "        return 'repeat'\n",
    "    elif search(r'\\bmore\\b', utterance):\n",
    "        return 'reqmore'\n",
    "    elif search(r'\\bstart\\b', utterance):\n",
    "        return 'restart'\n",
    "    elif search(r'\\bokay\\b|\\bkay\\b',utterance):\n",
    "        return 'ack'\n",
    "    else:\n",
    "        return 'inform'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d25a7ff",
   "metadata": {},
   "source": [
    "## Building Classifier Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a70b39d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0, max_iter=400),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18ded046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "11472    0\n",
      "25465    3\n",
      "8867     3\n",
      "25417    4\n",
      "24660    0\n",
      "        ..\n",
      "9372     6\n",
      "7291     3\n",
      "17728    3\n",
      "7293     0\n",
      "17673    7\n",
      "Name: label_id, Length: 21675, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, # scale the words frequency in logarithmic scale\n",
    "                        min_df=5, # remove the words which has occurred in less than ‘min_df’ number of files\n",
    "                        ngram_range=(1, 2), # don't know what role n-grams play in vectorisation\n",
    "                        stop_words='english', # it removes stop words which are predefined in ‘english’.\n",
    "                        lowercase=True # everything to lowercase\n",
    "                        )\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train).toarray()\n",
    "X_test_tfid = tfidf.fit_transform(X_test).toarray()\n",
    "\n",
    "print(X_train_tfid)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b183f9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sushii/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:684: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/sushii/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:684: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/sushii/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:684: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "CV = 2\n",
    "entries = []\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "\n",
    "for model in models:\n",
    "  model_name = model.__class__.__name__\n",
    "  accuracies = cross_val_score(model, X_train_tfid, y_train, scoring='accuracy')\n",
    "  for fold_idx, accuracy in enumerate(accuracies):\n",
    "    entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4592ba65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Standard deviation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.88000</td>\n",
       "      <td>0.002394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.85707</td>\n",
       "      <td>0.001920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.68286</td>\n",
       "      <td>0.025147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Mean Accuracy  Standard deviation\n",
       "model_name                                               \n",
       "LogisticRegression            0.88000            0.002394\n",
       "MultinomialNB                 0.85707            0.001920\n",
       "RandomForestClassifier        0.68286            0.025147"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_accuracy = cv_df.groupby('model_name').accuracy.mean()\n",
    "std_accuracy = cv_df.groupby('model_name').accuracy.std()\n",
    "\n",
    "acc = pd.concat([mean_accuracy, std_accuracy], axis= 1, \n",
    "          ignore_index=True)\n",
    "acc.columns = ['Mean Accuracy', 'Standard deviation']\n",
    "\n",
    "acc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db26e0f",
   "metadata": {},
   "source": [
    "seems like LogisticRegression is the best or we can tweek the hyperparameters more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af0fd468",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'moderately priced restaurant in the north part of town'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1138\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1138\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1146\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1070\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1071\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1072\u001b[0m     )\n\u001b[0;32m-> 1074\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1092\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    854\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    860\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:872\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;124;03m    Return the values as a NumPy array.\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;124;03m          dtype='datetime64[ns]')\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'moderately priced restaurant in the north part of town'"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=0, max_iter=400)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b7750b",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c568bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc8ecda",
   "metadata": {},
   "source": [
    "### Baseline Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c7120b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(labels,predictions):\n",
    "    \"\"\"Plots the confusion matrix\n",
    "    Arguments:\n",
    "    labels: array-like of shape (n_samples,)\n",
    "    predictions: array-like of shape (n_samples,)\n",
    "    Returns\n",
    "    -------\n",
    "    plot\n",
    "        plots the confusion matrix\n",
    "    \"\"\"\n",
    "    plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "    plt.rcParams['figure.figsize'] = [10, 10]\n",
    "    plt.rcParams['font.size'] = 8\n",
    "    sklearn.metrics.ConfusionMatrixDisplay.from_predictions(labels,predictions)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19457169",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rules' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m (\u001b[43mrules\u001b[49m(df))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbaselineAccuracy\u001b[39m(predictions, df):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124;03m\"\"\"Calculates the accuracy\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m        Arguments:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m        predictions: list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m        Returns the accuracy\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rules' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = (rules(df))\n",
    "def baselineAccuracy(predictions, df):\n",
    "    \"\"\"Calculates the accuracy\n",
    "        Arguments:\n",
    "        predictions: list\n",
    "        df: a pandas dataframe that contains a column named text with utterances.\n",
    "        Returns\n",
    "        -------\n",
    "    Returns:\n",
    "        Returns the accuracy\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for i in range(0,len(predictions)):\n",
    "        \n",
    "        if(predictions[i].lower() == df.loc[i,'label'].lower()):\n",
    "            count += 1\n",
    "    return \"Accuracy: \"+str(round(count / len(predictions)*100,1))+\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineAccuracy(predictions, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d15406",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(df['label'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c2074e",
   "metadata": {},
   "outputs": [],
   "source": [
    " def metrics_overview(labels, predictions):\n",
    "        \"\"\"Prints metrics\n",
    "        Arguments:\n",
    "        labels: array-like of shape (n_samples,)\n",
    "        predictions: array-like of shape (n_samples,)\n",
    "        \n",
    "        Prints different metrics related to the confusion matrix.\n",
    "        \"\"\"\n",
    "        edges_confusion_matrix = sklearn.metrics.confusion_matrix(labels,predictions)\n",
    "\n",
    "        FP = edges_confusion_matrix.sum(axis=0) - np.diag(edges_confusion_matrix)  \n",
    "        \n",
    "        FN = edges_confusion_matrix.sum(axis=1) - np.diag(edges_confusion_matrix)\n",
    "        \n",
    "        TP = np.diag(edges_confusion_matrix)\n",
    "        \n",
    "        TN = edges_confusion_matrix.sum() - (FP + FN + TP)\n",
    "        \n",
    "        \n",
    "        # Sensitivity, hit rate, recall, or true positive rate\n",
    "        TPR = TP/(TP+FN)\n",
    "        print('TPR',TPR)\n",
    "        print('Average TPR',np.average(TPR))\n",
    "        print('_______________________________')\n",
    "        # Specificity or true negative rate\n",
    "        TNR = TN/(TN+FP)\n",
    "        print('TNR',TNR)\n",
    "        print('Average TNR',np.average(TNR))\n",
    "        print('_______________________________')\n",
    "\n",
    "        # Precision or positive predictive value\n",
    "        PPV = TP/(TP+FP)\n",
    "        print('PPV',PPV)\n",
    "        print('Average PPV',np.average(PPV))\n",
    "        print('_______________________________')\n",
    "\n",
    "        # Negative predictive value\n",
    "        NPV = TN/(TN+FN)\n",
    "        print('NPV',NPV)\n",
    "        print('Average NPV',np.average(NPV))\n",
    "        print('_______________________________')\n",
    "\n",
    "        # Fall out or false positive rate\n",
    "        FPR = FP/(FP+TN)\n",
    "        print('FPR',FPR)\n",
    "        print('Average FPR',np.average(FPR))\n",
    "        print('_______________________________')\n",
    "\n",
    "        # False negative rate\n",
    "        FNR = FN/(TP+FN)\n",
    "        print('FNR',FNR)\n",
    "        print('Average FNR',np.average(FNR))\n",
    "        print('_______________________________')\n",
    "\n",
    "        # False discovery rate\n",
    "        FDR = FP/(TP+FP)\n",
    "        print('FDR',FDR)\n",
    "        print('Average FDR',np.average(FDR))\n",
    "        print('_______________________________')\n",
    "\n",
    "        # Overall accuracy\n",
    "        ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "        print('ACC',ACC)\n",
    "        print('Average ACC',np.average(ACC))\n",
    "        print('_______________________________')\n",
    "\n",
    "        F1 = 2*((PPV*TPR)/(PPV+TPR))\n",
    "        F1 = F1[~np.isnan(F1)]\n",
    "        print('F1',F1)\n",
    "        print('Average F1',np.average(F1))\n",
    "        print('_______________________________')\n",
    "        print((FP+FN)/(TP+FP+FN+TN))\n",
    "        \n",
    "metrics_overview(df['label'],predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e77ac18",
   "metadata": {},
   "source": [
    "### Proper Models (Random Forest, Multinomial NB, Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e503763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(label_test, label_pred, \n",
    "                                    target_names= df['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12efea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "conf_mat = confusion_matrix(label_test, label_pred)\n",
    "plt.figure(figsize = (20,5))\n",
    "sns.heatmap(conf_mat, annot=True, cmap='Greens', fmt='d',\n",
    "            xticklabels=label_dict.label.values, \n",
    "            yticklabels=label_dict.label.values)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bbba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19712c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('label').describe().sort_values(('text','count'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
