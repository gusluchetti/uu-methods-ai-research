{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb1a302",
   "metadata": {},
   "source": [
    "# WIP - Restaurant Recommendation Dialog System\n",
    "\n",
    "## Members:\n",
    "- Karpiński, R.R. (Rafał)\n",
    "- Pavan, L. (Lorenzo)\n",
    "- Rodrigues Luchetti, G.L. (Gustavo)\n",
    "- Teunissen, N.D. (Niels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002f13b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "\n",
    "from re import search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ee2b71",
   "metadata": {},
   "source": [
    "## Reading 'dialog_acts.dat' Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d20aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dialog_acts.dat', 'r') as f:\n",
    "    data = f.readlines()\n",
    "    data = list(map(lambda x: x.rstrip(\"\\n\").split(\" \", 1), data))\n",
    "    \n",
    "df = pd.DataFrame(np.array(data), columns = ['label', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c08e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inform</td>\n",
       "      <td>im looking for a moderately priced restaurant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inform</td>\n",
       "      <td>any part of town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inform</td>\n",
       "      <td>bistro food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                               text\n",
       "0  inform  im looking for a moderately priced restaurant ...\n",
       "1  inform                                   any part of town\n",
       "2  inform                                        bistro food"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c28b517",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "\n",
    "Looking for null values, irrelevant or noisy text (literally, removing 'tv_noise' and 'noise') and repeated values. Formatting labels into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "485147b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>confirm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>affirm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thankyou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>reqalts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>negate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>repeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>restart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>reqmore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label\n",
       "label_id          \n",
       "0           inform\n",
       "1          confirm\n",
       "2           affirm\n",
       "3          request\n",
       "4         thankyou\n",
       "5             null\n",
       "6              bye\n",
       "7          reqalts\n",
       "8           negate\n",
       "9            hello\n",
       "10          repeat\n",
       "11             ack\n",
       "12         restart\n",
       "13            deny\n",
       "14         reqmore"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label_id'] = df['label'].factorize()[0]\n",
    "label_dict = df[['label','label_id']].drop_duplicates().set_index('label_id')\n",
    "\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1566f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# X - independent features (excluding target variable).\n",
    "# y - dependent variables (target we're looking to predict).\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], df['label_id'], test_size=0.15, random_state=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca8dac68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "11472    0\n",
      "25465    3\n",
      "8867     3\n",
      "25417    4\n",
      "24660    0\n",
      "        ..\n",
      "9372     6\n",
      "7291     3\n",
      "17728    3\n",
      "7293     0\n",
      "17673    7\n",
      "Name: label_id, Length: 21675, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, # scale the words frequency in logarithmic scale\n",
    "                        min_df=5, # remove the words which has occurred in less than ‘min_df’ number of files\n",
    "                        ngram_range=(1, 2), # don't know what role n-grams play in vectorisation\n",
    "                        stop_words='english', # it removes stop words which are predefined in ‘english’.\n",
    "                        lowercase=True # everything to lowercase\n",
    "                        )\n",
    "\n",
    "features = tfidf.fit_transform(text_train).toarray()\n",
    "targets = label_train\n",
    "\n",
    "print(features)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6598f9c",
   "metadata": {},
   "source": [
    "## Building Baseline Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf583c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def BaselineRuleBased(dataframe):\n",
    "    \"\"\"\n",
    "    Rule-based prediction of dialog acts based on utterances.\n",
    "    Arguments:\n",
    "        dataframe: a pandas dataframe that contains a column named text with utterances.\n",
    "        \n",
    "    Returns:\n",
    "        Returns a list of predictions about the label (dialog act) of the utterances.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for i in range(0,len(dataframe)):\n",
    "        if search(r'\\bhow about\\b|\\bwhat about\\b|\\banything else\\b|\\bare there\\b|\\bis there\\b|\\bwhat else\\b', df.loc[i,'text']):\n",
    "            predictions.append('reqalts')\n",
    "        elif search(r'\\byes\\b|\\byeah\\b|\\bcorrect\\b',df.loc[i,'text']):\n",
    "            predictions.append('affirm')\n",
    "        elif search(r'\\bthank you\\b', df.loc[i,'text']):\n",
    "            predictions.append('thankyou')\n",
    "        elif search(r'\\bgoodbye\\b|\\bbye\\b', df.loc[i,'text']):\n",
    "            predictions.append('bye')\n",
    "        elif search(r'\\bdoes it\\b|\\bis it\\b|\\bdo they\\b|\\bis that\\b|\\bis there\\b', df.loc[i,'text']):\n",
    "            predictions.append('confirm')\n",
    "        elif search(r'\\bwhat is\\b|\\bwhats\\b|\\bmay i\\b|\\bcould i\\b|\\bwhat\\b|\\bprice range\\b|\\bpost code\\b|\\btype of\\b|\\baddress\\b|\\bphone number\\b|\\bcan i\\b|\\bcould i\\b|\\bcould you\\b|\\bdo you\\b|\\bi want+.address\\b|\\bi want+.phone\\b|\\bi would\\b|\\bwhere is\\b', df.loc[i,'text']):\n",
    "            predictions.append('request')\n",
    "        elif search(r'\\bno\\b|\\bnot\\b', df.loc[i,'text']):\n",
    "            predictions.append('negate')\n",
    "        elif search(r'\\blooking for\\b|\\bdont care\\b|\\bdoesnt matter\\b|\\bexpensive\\b|\\bcheap\\b|\\bmoderate\\b|\\bi need\\b|\\bi want\\b|\\bfood\\b|\\bnorth\\b',df.loc[i,'text']):\n",
    "            predictions.append('inform')\n",
    "        elif search(r'\\bdont\\b', df.loc[i,'text']):\n",
    "            predictions.append('deny')\n",
    "        elif search(r'\\bhello\\b', df.loc[i,'text']):\n",
    "            predictions.append('hello')\n",
    "        elif search(r'\\brepeat\\b', df.loc[i,'text']):\n",
    "            predictions.append('repeat')\n",
    "        elif search(r'\\bmore\\b', df.loc[i,'text']):\n",
    "            predictions.append('reqmore')\n",
    "        elif search(r'\\bstart\\b', df.loc[i,'text']):\n",
    "            predictions.append('restart')\n",
    "        elif search(r'\\bokay\\b|\\bkay\\b',df.loc[i,'text']):\n",
    "            predictions.append('ack')\n",
    "        else:\n",
    "            predictions.append('inform')\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d25a7ff",
   "metadata": {},
   "source": [
    "## Building Classifier Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70b39d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0, max_iter=400),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b183f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "CV = 2\n",
    "entries = []\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "\n",
    "for model in models:\n",
    "  model_name = model.__class__.__name__\n",
    "  accuracies = cross_val_score(model, features, labels, scoring='accuracy')\n",
    "  for fold_idx, accuracy in enumerate(accuracies):\n",
    "    entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4592ba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_accuracy = cv_df.groupby('model_name').accuracy.mean()\n",
    "std_accuracy = cv_df.groupby('model_name').accuracy.std()\n",
    "\n",
    "acc = pd.concat([mean_accuracy, std_accuracy], axis= 1, \n",
    "          ignore_index=True)\n",
    "acc.columns = ['Mean Accuracy', 'Standard deviation']\n",
    "\n",
    "acc # seems like LogisticRegression is the best or we can tweek the hyperparameters more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5993d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = tfidf.transform(text_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0fd468",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=0, max_iter=400)\n",
    "model.fit(features, labels)\n",
    "label_pred = model.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b7750b",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc8ecda",
   "metadata": {},
   "source": [
    "### Baseline Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7120b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e77ac18",
   "metadata": {},
   "source": [
    "### Proper Models (Random Forest, Multinomial NB, Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e503763",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m models \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mRandomForestClassifier\u001b[49m(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m      3\u001b[0m     MultinomialNB(),\n\u001b[1;32m      4\u001b[0m     LogisticRegression(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m),\n\u001b[1;32m      5\u001b[0m ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(label_test, label_pred, \n",
    "                                    target_names= df['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12efea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "conf_mat = confusion_matrix(label_test, label_pred)\n",
    "plt.figure(figsize = (20,5))\n",
    "sns.heatmap(conf_mat, annot=True, cmap='Greens', fmt='d',\n",
    "            xticklabels=label_dict.label.values, \n",
    "            yticklabels=label_dict.label.values)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bbba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19712c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('label').describe().sort_values(('text','count'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
