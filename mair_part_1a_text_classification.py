# -*- coding: utf-8 -*-
""".py MAIR Part 1a: text classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1skTywLiRoqIC-oyafVpTIJF2hS0XSdvO
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression

def get_dataset(path):
  """
  arg: dataset file path
  
  return: DataFrame of dataset
  """
  with open(path, 'r') as f:
    data = f.readlines()
    data = list(map(lambda x: x.rstrip("\n").split(" ", 1), data))
  df = pd.DataFrame(np.array(data), columns = ['label', 'text'])
  return df

def preprocess(dataset):
  """
  Preprocesses the dataset

  arg: DataFrame dataset
  
  return: dataset
  """
  return dataset

def train_logistic_regression_model(df):
  """
  Trains Logistic Regression classifier

  arg: DataFrame dataset
  
  return: tuple of a trained,fitted model and a NLP vectorizer/transformer
  """
  text_train, text_test, label_train, label_test = train_test_split(df['text'], df['label_id'], test_size=0.15, random_state=10)

  tfidf = TfidfVectorizer(sublinear_tf=True, #scale the words frequency in logarithmic scale
                        min_df=5, #remove the words which has occurred in less than ‘min_df’ number of files
                        ngram_range=(1, 2), #dont know what role n-grams play in vectorisation
                        stop_words='english', #it removes stop words which are predefined in ‘english’.
                        lowercase=True #everything to lowercase
                        )
  features = tfidf.fit_transform(text_train).toarray()
  labels = label_train

  model = LogisticRegression(random_state=0, max_iter=400)
  model.fit(features, labels)

  features_test = tfidf.transform(text_test).toarray()
  label_pred = model.predict(features_test)

  return (model, tfidf)

def train_NB_classifier_model(df):
  """
  Trains Naive Bayes classifier

  arg: DataFrame dataset
  
  return: tuple of a trained,fitted model and a NLP vectorizer/transformer
  """
  text_train, text_test, label_train, label_test = train_test_split(df['text'], df['label_id'], test_size=0.15, random_state=10)

  tfidf = TfidfVectorizer(sublinear_tf=True, #scale the words frequency in logarithmic scale
                        min_df=5, #remove the words which has occurred in less than ‘min_df’ number of files
                        ngram_range=(1, 2), #dont know what role n-grams play in vectorisation
                        stop_words='english', #it removes stop words which are predefined in ‘english’.
                        lowercase=True #everything to lowercase
                        )
  features = tfidf.fit_transform(text_train).toarray()
  labels = label_train

  model = MultinomialNB()
  model.fit(features, labels)

  features_test = tfidf.transform(text_test).toarray()
  label_pred = model.predict(features_test)

  return (model, tfidf)

def classify_utterance_1(ut, dataset):
  """
  Classify the utterance as most frequent label in the dataset.

  arg:
    ut - the utterance
    dataset - DataFrame with dataset
    
  return: label of the utterance
  """
  classified_label = dataset['label'].mode()
  return classified_label


def classify_utterance_2(ut):
  """
  Rule-based prediction of a dialog act, that classifies the utterancewith a label.

  arg:
    ut - the utterance
    dataset - DataFrame with dataset

  return: predicted dialog act/ label of the utterance
  """
  utterance = utterance.lower()
  if search(r'\bhow about\b|\bwhat about\b|\banything else\b|\bare there\b|\bis there\b|\bwhat else\b', utterance):
      return 'reqalts'
  elif search(r'\byes\b|\byeah\b|\bcorrect\b',utterance):
      return 'affirm'
  elif search(r'\bthank you\b', utterance):
      return 'thankyou'
  elif search(r'\bgoodbye\b|\bbye\b', utterance):
      return 'bye'
  elif search(r'\bdoes it\b|\bis it\b|\bdo they\b|\bis that\b|\bis there\b', utterance):
      return 'confirm'
  elif search(r'\bwhat is\b|\bwhats\b|\bmay i\b|\bcould i\b|\bwhat\b|\bprice range\b|\bpost code\b|\btype of\b|\baddress\b|\bphone number\b|\bcan i\b|\bcould i\b|\bcould you\b|\bdo you\b|\bi want+.address\b|\bi want+.phone\b|\bi would\b|\bwhere is\b', utterance):
      return 'request'
  elif search(r'\bno\b|\bnot\b', utterance):
      return 'negate'
  elif search(r'\blooking for\b|\bdont care\b|\bdoesnt matter\b|\bexpensive\b|\bcheap\b|\bmoderate\b|\bi need\b|\bi want\b|\bfood\b|\bnorth\b',utterance):
      return 'inform'
  elif search(r'\bdont\b', utterance):
      return 'deny'
  elif search(r'\bhello\b|\bhi\b|\bhey\b', utterance):
      return 'hello'
  elif search(r'\brepeat\b', utterance):
      return 'repeat'
  elif search(r'\bmore\b', utterance):
      return 'reqmore'
  elif search(r'\bstart\b', utterance):
      return 'restart'
  elif search(r'\bokay\b|\bkay\b',utterance):
      return 'ack'
  else:
      return 'inform'


def classify_utterance_3(ut, classifier, processor, labels):
  """
  Classify the utterance based on an ML model. for that purpose preprocess the utterance and feed it to model preditor.

  arg: 
    ut - utterance, 
    classifier - ML model, 
    processor - NLP vectorizer/transformer, 
    labels - label_id mapping

  return: label of the utterance
  """
  ready_ut = processor.transform([ut]).toarray()
  classified_label_id = classifier.predict(ready_ut)[0]
  classified_label = labels.loc[classified_label_id][0]
  return classified_label


def bot(model, utterance_processor, label_dict):
  """
  Runs a bot which (until 'bye123' is written)
  1.takes user input
  2.classifies the input text into an action label
  3.prints back out that label and text

  arg: 
    model - ML model for utterance classification
    utterance_processor - NLP vectorizer/processor
    label_dict - label_id decoder

  return: None
  """
  finished = False
  print(f'Hi! To exit enter "bye123"')
  while not finished:
    utterance = input('>').lower()
    if 'bye123' in utterance:
      finished = True
      print(f'Bye!')
      continue
    label = classify_utterance_3(utterance, model, utterance_processor, label_dict)
    print(f'utterance:{utterance}\nlabel:{label}')

def main():
  """
  Prepares the dataset, model and runs the bot
  """
  df = get_dataset('dialog_acts.dat')
  df = preprocess(df)
  df['label_id'] = df['label'].factorize()[0]
  label_dict = df[['label','label_id']].drop_duplicates().set_index('label_id')
  model, vectorizer = train_logistic_regression_model(df)
  #model, vectorizer = train_NB_classifier_model(df)
  bot(model, vectorizer, label_dict)

main()